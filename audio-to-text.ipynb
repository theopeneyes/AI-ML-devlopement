{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOQ6PjIcL/yMg2trrYGtcAr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7f3f6b4a7dfa43b6ba4f55de2ec284a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d0d543aeef34fd79299dd80d8d28dc7","IPY_MODEL_56b536270e164826b55dd3646129458e","IPY_MODEL_9115e7a999eb47f9a3b96006032e5a86"],"layout":"IPY_MODEL_c021ed0a6a414c33a27a27f7d97c76dc"}},"0d0d543aeef34fd79299dd80d8d28dc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3613749033764ec08e94199d59aa3375","placeholder":"​","style":"IPY_MODEL_5743ac519c7c4f20933bbb3d0177a39a","value":"Loading checkpoint shards: 100%"}},"56b536270e164826b55dd3646129458e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38e203329e24dee884d6f85c646f992","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13390a1d27fe42e4a49e5816cb38dd48","value":3}},"9115e7a999eb47f9a3b96006032e5a86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1e0c8bf1f4944fba42bca117f156613","placeholder":"​","style":"IPY_MODEL_baf247b5091847c8ae2ecf6f0e7f0393","value":" 3/3 [00:12&lt;00:00,  4.09s/it]"}},"c021ed0a6a414c33a27a27f7d97c76dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3613749033764ec08e94199d59aa3375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5743ac519c7c4f20933bbb3d0177a39a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d38e203329e24dee884d6f85c646f992":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13390a1d27fe42e4a49e5816cb38dd48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1e0c8bf1f4944fba42bca117f156613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf247b5091847c8ae2ecf6f0e7f0393":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6d3McyYrx0hB","executionInfo":{"status":"ok","timestamp":1716294734471,"user_tz":-330,"elapsed":6629,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"1147f422-ae97-4076-bd01-5817ae08eadb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers[torch] datasets[audio]\n","!pip install librosa\n","!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFFWz6DayI5Z","executionInfo":{"status":"ok","timestamp":1716299109687,"user_tz":-330,"elapsed":21772,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"5f98f52d-8328-4fb3-e53b-cacd8957b01d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.2)\n","Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.10/dist-packages (2.19.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.30.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2.0.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.9.5)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.2.post1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.58.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3.7)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.0.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2024.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->datasets[audio]) (4.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"]}]},{"cell_type":"code","source":["!pip install accelerate\n","!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSFAiywxn19Q","executionInfo":{"status":"ok","timestamp":1716299120067,"user_tz":-330,"elapsed":10385,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"d0f4c188-4912-4b99-ff34-e1235e543f2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Looking in indexes: https://pypi.org/simple/\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","import librosa\n","import torch\n","import huggingface_hub as hub\n","import time\n","import re\n","import pandas as pd\n","import os\n","import re\n","\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    # BitsAndBytesConfig,\n",")\n","base_path = \"/content/drive/MyDrive/AudioTesting\"\n","\n","audio_files = os.listdir(os.path.join(base_path, \"AudioFiles\"))\n","if not os.path.exists(os.path.join(base_path, \"AudioLogs\")):\n","    os.makedirs(os.path.join(base_path, \"AudioLogs\"))\n","\n","df = pd.DataFrame(columns=[\n","    \"AUDIO_FILE_NAME\",\n","    \"ASR_MODEL_NAME\",\n","    \"TG_MODEL_NAME\",\n","    \"ASR_LOADING_DURATION\",\n","    \"ASR_S2T\",\n","    \"TG_LOADING_DURATION\",\n","    \"TG_DURATION\",\n","    \"TOTAL_DURATION\",\n","    \"S2T_OUTPUT\",\n","    \"GeneratedQNA\",\n","])\n","\n","ultra_offset = time.time()\n","\n","hub.login(token=\"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\")\n","checkpoint = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","audio_checkpoint = \"openai/whisper-tiny\"\n","\n","# config = BitsAndBytesConfig(\n","#    load_in_4bit=True,\n","#    bnb_4bit_quant_type=\"nf4\",\n","#    bnb_4bit_use_double_quant=True,\n","#    bnb_4bit_compute_dtype=torch.bfloat16\n","# )\n","\n","# loading models required for compute\n","offset = time.time()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","whisper = pipeline(\"automatic-speech-recognition\", device = device,\n","                        model=audio_checkpoint)\n","\n","audio_load_duration = time.time() - offset\n","\n","offset = time.time()\n","mistral_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","mistral = AutoModelForCausalLM.from_pretrained(\n","    checkpoint, # quantization_config=config,\n","    device_map=device,\n",")\n","model_load_duration = time.time() - offset\n","\n","mistral_pipe = pipeline(\"text-generation\",\n","                        model=mistral, tokenizer=mistral_tokenizer,do_sample=True,\n","                        max_new_tokens=1024, device_map=device, temperature=0.1)\n","\n","ultra_duration = time.time() - ultra_offset\n","\n","for file_name in audio_files:\n","    generation_offset = time.time()\n","    filepath = os.path.join(base_path, \"AudioFiles\", file_name)\n","    audio, sr = librosa.load(filepath, sr=16_000)\n","    offset = time.time()\n","    output = whisper(\n","        audio,\n","        return_timestamps=True,\n","        generate_kwargs = {\"task\": \"transcribe\"},\n","        chunk_length_s=30,\n","    )\n","\n","    audio_to_text_duration = time.time() - offset\n","\n","    item = output[\"text\"]\n","\n","    prompt = \"Generate as many as possible difficulty level hard Multiple choice questions with four options and answer using this text:\"+\" \"+item+'''\\n Give me output in this JSON array format:[{\"question\": string, \"options\":List[string], \"answer\":string}]'''\n","    prompt_template= f'''[INST] <s> You have Phd in history and best in generating Multiple choice questions with demanded JSON format. </s> {prompt}[/INST]'''\n","\n","    offset = time.time()\n","    mcqs = mistral_pipe(prompt_template)\n","    text_to_qna_duration = time.time() - offset\n","\n","    generation_duration = time.time() - generation_offset\n","    loading_minutes, loading_seconds = divmod(ultra_duration, 60)\n","    generation_minutes, generation_seconds = divmod(generation_duration, 60)\n","    print(\"total duration audio to qna : %d mins %d seconds\" % (generation_minutes, generation_seconds))\n","\n","    pattern = r\"{(?:[^{}]|)*}\"\n","    matches = re.findall(pattern, mcqs[0][\"generated_text\"])\n","    qnas = \"\\n\".join(matches) if matches != [] else \"No qna generated\"\n","\n","    dirs = filepath.split(\"/\")\n","    df1 = pd.DataFrame({\n","        \"AUDIO_FILE_NAME\": [dirs[-2] + \"/\" + dirs[-1]],\n","        \"ASR_MODEL_NAME\": [audio_checkpoint],\n","        \"TG_MODEL_NAME\": [checkpoint],\n","        \"ASR_LOADING_DURATION\": [\"{} mins {:.2f} seconds\".format(*divmod(audio_load_duration, 60))],\n","        \"ASR_S2T\": [\"{} mins {:.2f} seconds\".format(*divmod(audio_to_text_duration, 60))],\n","        \"TG_LOADING_DURATION\": [\"{} mins {:.2f} seconds\".format(*divmod(model_load_duration, 60))],\n","        \"TG_DURATION\": [\"{} mins {:.2f} seconds\".format(*divmod(text_to_qna_duration, 60))],\n","        \"TOTAL_DURATION\": [\"{} mins {:.2f} seconds\".format(*divmod(generation_duration, 60))],\n","        \"S2T_OUTPUT\": output[\"text\"],\n","        \"GeneratedQNA\": [qnas],\n","    })\n","\n","    df = pd.concat([df, df1])\n","    df.to_excel(os.path.join(base_path, \"AudioLogs/AudioLogs.xlsx\"), index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329,"referenced_widgets":["7f3f6b4a7dfa43b6ba4f55de2ec284a3","0d0d543aeef34fd79299dd80d8d28dc7","56b536270e164826b55dd3646129458e","9115e7a999eb47f9a3b96006032e5a86","c021ed0a6a414c33a27a27f7d97c76dc","3613749033764ec08e94199d59aa3375","5743ac519c7c4f20933bbb3d0177a39a","d38e203329e24dee884d6f85c646f992","13390a1d27fe42e4a49e5816cb38dd48","d1e0c8bf1f4944fba42bca117f156613","baf247b5091847c8ae2ecf6f0e7f0393"]},"id":"SiwPYfaUyVSV","executionInfo":{"status":"ok","timestamp":1716299323786,"user_tz":-330,"elapsed":160766,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"550a8b22-7ba5-4d6a-b186-8be9d04ce5a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3f6b4a7dfa43b6ba4f55de2ec284a3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Time taken: 2.0 minutes  40.25 seconds\n"]}]},{"cell_type":"code","source":["df.to_excel(os.path.join(base_path, \"AudioLogs.xlsx\"), index=False)"],"metadata":{"id":"qyjX0uNu11Gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"huMYoqTr1q-T","executionInfo":{"status":"ok","timestamp":1716298387266,"user_tz":-330,"elapsed":527,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"4b020a6c-0c2f-48c1-f731-4ebc47ffb931"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      AUDIO_FILE_NAME  \\\n","0   nature-of-society-individuals-and-groups-audio...   \n","1   nature-of-society-individuals-and-groups-audio...   \n","2   nature-of-society-individuals-and-groups-audio...   \n","3   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","4   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","5   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","6   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","7   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","8   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","9   ASR/Mod-01 Lec-03 Nature of society Individual...   \n","10  ASR/Mod-01 Lec-03 Nature of society Individual...   \n","11  ASR/Mod-01 Lec-03 Nature of society Individual...   \n","12  ASR/Mod-01 Lec-03 Nature of society Individual...   \n","13  ASR/Mod-01 Lec-03 Nature of society Individual...   \n","14  ASR/Mod-01 Lec-03 Nature of society Individual...   \n","15                     AudioFiles/javascript_mock.mp3   \n","16                   AudioFiles/infosys_interview.mp3   \n","17                    AudioFiles/campus_placement.mp3   \n","18                    AudioFiles/campus_placement.mp3   \n","19                       AudioFiles/tcs_interview.mp3   \n","20                                AudioFiles/lstm.mp3   \n","21                                AudioFiles/lstm.mp3   \n","22                                 AudioFiles/rnn.mp3   \n","0                                  AudioFiles/rnn.mp3   \n","\n","             ASR_MODEL_NAME                        TG_MODEL_NAME  \\\n","0      openai/whisper-small   mistralai/Mistral-7B-Instruct-v0.2   \n","1   openai/whisper-large-v3   mistralai/Mistral-7B-Instruct-v0.2   \n","2       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","3       openai/whisper-base   mistralai/Mistral-7B-Instruct-v0.2   \n","4       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","5       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","6       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","7       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","8       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","9       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","10      openai/whisper-tiny  meta-llama/Meta-Llama-3-8B-Instruct   \n","11      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","12      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","13      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","14      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","15      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","16      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","17      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","18      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","19      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","20      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","21      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","22      openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","0       openai/whisper-tiny   mistralai/Mistral-7B-Instruct-v0.2   \n","\n","                      EMBEDDING_MODEL_NAME    ASR_LOADING_DURATION  \\\n","0   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 39.40 seconds   \n","1   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 43.84 seconds   \n","2   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 27.04 seconds   \n","3   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 19.28 seconds   \n","4   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 12.18 seconds   \n","5   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 15.79 seconds   \n","6   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 15.42 seconds   \n","7   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 15.19 seconds   \n","8   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 32.81 seconds   \n","9   sentence-transformers/all-MiniLM-L6-v2  0.0 mins 34.79 seconds   \n","10  sentence-transformers/all-MiniLM-L6-v2  0.0 mins 17.30 seconds   \n","11  sentence-transformers/all-MiniLM-L6-v2  0.0 mins 18.42 seconds   \n","12  sentence-transformers/all-MiniLM-L6-v2  0.0 mins 15.08 seconds   \n","13  sentence-transformers/all-MiniLM-L6-v2  0.0 mins 12.98 seconds   \n","14                                     NaN   0.0 mins 9.63 seconds   \n","15                                     NaN  0.0 mins 11.28 seconds   \n","16                                     NaN   0.0 mins 9.43 seconds   \n","17                                     NaN  0.0 mins 11.10 seconds   \n","18                                     NaN   0.0 mins 9.18 seconds   \n","19                                     NaN  0.0 mins 16.59 seconds   \n","20                                     NaN  0.0 mins 12.83 seconds   \n","21                                     NaN  0.0 mins 11.16 seconds   \n","22                                     NaN  0.0 mins 16.13 seconds   \n","0                                     None  0.0 mins 13.13 seconds   \n","\n","                   ASR_S2T     TG_LOADING_DURATION              TG_DURATION  \\\n","0   2.0 mins 12.76 seconds  2.0 mins 13.01 seconds  13.0 mins 25.96 seconds   \n","1   6.0 mins 32.19 seconds  2.0 mins 26.82 seconds   4.0 mins 31.76 seconds   \n","2    1.0 mins 1.36 seconds  2.0 mins 15.83 seconds   5.0 mins 30.72 seconds   \n","3   1.0 mins 29.89 seconds  1.0 mins 12.10 seconds   9.0 mins 45.20 seconds   \n","4    1.0 mins 8.68 seconds  1.0 mins 20.21 seconds   7.0 mins 28.07 seconds   \n","5    1.0 mins 9.23 seconds  1.0 mins 24.34 seconds   5.0 mins 29.20 seconds   \n","6   1.0 mins 10.78 seconds  1.0 mins 19.33 seconds   5.0 mins 33.74 seconds   \n","7    1.0 mins 9.74 seconds  1.0 mins 18.81 seconds   5.0 mins 15.32 seconds   \n","8   1.0 mins 12.72 seconds  3.0 mins 46.97 seconds    7.0 mins 8.06 seconds   \n","9   1.0 mins 13.49 seconds  2.0 mins 58.15 seconds   7.0 mins 38.80 seconds   \n","10  1.0 mins 12.76 seconds   3.0 mins 3.79 seconds   7.0 mins 41.26 seconds   \n","11  1.0 mins 15.76 seconds  1.0 mins 29.36 seconds   5.0 mins 37.52 seconds   \n","12  1.0 mins 12.03 seconds  1.0 mins 26.99 seconds   3.0 mins 52.08 seconds   \n","13  1.0 mins 13.92 seconds  1.0 mins 30.33 seconds   3.0 mins 40.21 seconds   \n","14  0.0 mins 49.86 seconds  0.0 mins 12.92 seconds   1.0 mins 58.69 seconds   \n","15   1.0 mins 6.84 seconds  0.0 mins 14.00 seconds   0.0 mins 57.40 seconds   \n","16  0.0 mins 41.36 seconds  0.0 mins 14.31 seconds   0.0 mins 52.23 seconds   \n","17  0.0 mins 50.31 seconds  0.0 mins 14.08 seconds   0.0 mins 40.31 seconds   \n","18  0.0 mins 50.67 seconds  0.0 mins 14.18 seconds   0.0 mins 45.60 seconds   \n","19  1.0 mins 41.34 seconds  0.0 mins 14.23 seconds   0.0 mins 38.43 seconds   \n","20  0.0 mins 40.68 seconds  0.0 mins 14.11 seconds   0.0 mins 49.84 seconds   \n","21  0.0 mins 41.05 seconds  0.0 mins 14.22 seconds    1.0 mins 7.19 seconds   \n","22  0.0 mins 55.62 seconds  0.0 mins 14.20 seconds   0.0 mins 28.30 seconds   \n","0   0.0 mins 56.00 seconds  0.0 mins 14.24 seconds   0.0 mins 30.05 seconds   \n","\n","   EMBEDDING_LOADING_DURATION           TOTAL_DURATION  \\\n","0       0.0 mins 2.05 seconds  18.0 mins 52.49 seconds   \n","1       0.0 mins 3.30 seconds  14.0 mins 39.68 seconds   \n","2       0.0 mins 2.73 seconds   9.0 mins 47.84 seconds   \n","3       0.0 mins 1.42 seconds  12.0 mins 48.54 seconds   \n","4       0.0 mins 1.02 seconds  10.0 mins 10.21 seconds   \n","5       0.0 mins 1.62 seconds   8.0 mins 20.88 seconds   \n","6       0.0 mins 1.41 seconds   8.0 mins 21.31 seconds   \n","7       0.0 mins 0.97 seconds    8.0 mins 0.67 seconds   \n","8       0.0 mins 2.79 seconds  12.0 mins 45.15 seconds   \n","9       0.0 mins 3.92 seconds  12.0 mins 33.11 seconds   \n","10      0.0 mins 1.79 seconds  12.0 mins 17.99 seconds   \n","11      0.0 mins 2.08 seconds   8.0 mins 44.12 seconds   \n","12      0.0 mins 1.53 seconds   6.0 mins 47.81 seconds   \n","13      0.0 mins 1.60 seconds   6.0 mins 39.15 seconds   \n","14                        NaN   3.0 mins 11.42 seconds   \n","15                        NaN   2.0 mins 29.73 seconds   \n","16                        NaN   1.0 mins 57.50 seconds   \n","17                        NaN   1.0 mins 55.97 seconds   \n","18                        NaN   1.0 mins 59.79 seconds   \n","19                        NaN   2.0 mins 50.75 seconds   \n","20                        NaN   1.0 mins 57.63 seconds   \n","21                        NaN   2.0 mins 13.79 seconds   \n","22                        NaN   1.0 mins 54.42 seconds   \n","0                        None   1.0 mins 53.59 seconds   \n","\n","                                           S2T_OUTPUT  \\\n","0    Well, friends, today we are going to discuss ...   \n","1    Well friends, today we are going to discuss t...   \n","2    Well first, today we are going to discuss the...   \n","3    Well, first today we are going to discuss the...   \n","4    Well first, today we are going to discuss the...   \n","5    Well first, today we are going to discuss the...   \n","6    Well first, today we are going to discuss the...   \n","7    Well first, today we are going to discuss the...   \n","8    Well first, today we are going to discuss the...   \n","9    Well first, today we are going to discuss the...   \n","10   Well first, today we are going to discuss the...   \n","11   Well first, today we are going to discuss the...   \n","12   Well first, today we are going to discuss the...   \n","13   Well first, today we are going to discuss the...   \n","14   Well first, today we are going to discuss the...   \n","15   Hello everyone, welcome back to another inter...   \n","16   Good afternoon sir. Hmm, pooruvi, are you ner...   \n","17   Kajal. Alo, good afternoon sir. How are you? ...   \n","18   Kajal. Alo, good afternoon sir. How are you? ...   \n","19   So, if you click points to be shared because ...   \n","20   So now we are going to discuss LSTM and we ar...   \n","21   So now we are going to discuss LSTM and we ar...   \n","22   Welcome to the next episode of the Nature of ...   \n","0    Welcome to the next episode of the Nature of ...   \n","\n","                                         GeneratedQNA  Question_count  \\\n","0   ['1. What is the definition of society accordi...              51   \n","1   ['1. What is the definition of society accordi...              20   \n","2   ['1. What is the definition of society accordi...              20   \n","3   [\"1. What is the definition of society accordi...              27   \n","4   ['1. What is the definition of society accordi...              24   \n","5   ['1. What is the definition of society accordi...              19   \n","6   ['1. What is the definition of society accordi...              21   \n","7   ['1. What is the definition of society accordi...              19   \n","8   ['1. What is the definition of society accordi...              21   \n","9   [\"1. What is the definition of society accordi...              21   \n","10  ['1. What is the definition of a group in soci...              13   \n","11  ['1. What is the definition of a group accordi...               9   \n","12  ['1. What is the definition of a group accordi...              10   \n","13  ['1. What is the definition of a group accordi...              19   \n","14  [{'generated_text': '[INST] <s> You have Phd i...               1   \n","15  [INST] <s> You have Phd in history and best in...               1   \n","16  [INST] <s> You have Phd in history and best in...               1   \n","17  [INST] <s> You have Phd in history and best in...               1   \n","18  [INST] <s> You have Phd in history and best in...               1   \n","19  [INST] <s> You have Phd in history and best in...               1   \n","20  [INST] <s> You have Phd in history and best in...               1   \n","21  [INST] <s> You have Phd in history and best in...               1   \n","22  [INST] <s> You have Phd in history and best in...               1   \n","0   [INST] <s> You have Phd in history and best in...               1   \n","\n","                                          PROMPT_USED  \\\n","0   You are an expert at creating questions based ...   \n","1   You are an expert at creating questions based ...   \n","2   You are an expert at creating questions based ...   \n","3   You are an expert at creating questions based ...   \n","4   You are an expert at creating questions based ...   \n","5   You are an expert at creating questions based ...   \n","6   You are an expert at creating questions based ...   \n","7   You are an expert at creating questions based ...   \n","8   You are an expert at creating questions based ...   \n","9   You are an expert at creating questions based ...   \n","10  input_variables=['text'] template='\\n    You a...   \n","11  input_variables=['text'] template='\\n    You a...   \n","12  input_variables=['text'] template='\\n    You a...   \n","13  You are an expert at creating questions based ...   \n","14                                                NaN   \n","15                                                NaN   \n","16                                                NaN   \n","17                                                NaN   \n","18                                                NaN   \n","19                                                NaN   \n","20                                                NaN   \n","21                                                NaN   \n","22                                                NaN   \n","0                                                 NaN   \n","\n","                                  REFINED_PROMPT_USED  \n","0    You are an expert at creating practice questi...  \n","1    You are an expert at creating practice questi...  \n","2    You are an expert at creating practice questi...  \n","3    You are an expert at creating practice questi...  \n","4    You are an expert at creating practice questi...  \n","5    You are an expert at creating practice questi...  \n","6    You are an expert at creating practice questi...  \n","7    You are an expert at creating practice questi...  \n","8    You are an expert at creating practice questi...  \n","9    You are an expert at creating practice questi...  \n","10  input_variables=['existing_answer', 'text'] te...  \n","11  input_variables=['existing_answer', 'text'] te...  \n","12  input_variables=['existing_answer', 'text'] te...  \n","13   You are an expert at creating practice questi...  \n","14                                                NaN  \n","15                                                NaN  \n","16                                                NaN  \n","17                                                NaN  \n","18                                                NaN  \n","19                                                NaN  \n","20                                                NaN  \n","21                                                NaN  \n","22                                                NaN  \n","0                                                 NaN  "],"text/html":["\n","  <div id=\"df-89fc3cd3-8060-49bc-80d3-a120a4fa2a14\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AUDIO_FILE_NAME</th>\n","      <th>ASR_MODEL_NAME</th>\n","      <th>TG_MODEL_NAME</th>\n","      <th>EMBEDDING_MODEL_NAME</th>\n","      <th>ASR_LOADING_DURATION</th>\n","      <th>ASR_S2T</th>\n","      <th>TG_LOADING_DURATION</th>\n","      <th>TG_DURATION</th>\n","      <th>EMBEDDING_LOADING_DURATION</th>\n","      <th>TOTAL_DURATION</th>\n","      <th>S2T_OUTPUT</th>\n","      <th>GeneratedQNA</th>\n","      <th>Question_count</th>\n","      <th>PROMPT_USED</th>\n","      <th>REFINED_PROMPT_USED</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nature-of-society-individuals-and-groups-audio...</td>\n","      <td>openai/whisper-small</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 39.40 seconds</td>\n","      <td>2.0 mins 12.76 seconds</td>\n","      <td>2.0 mins 13.01 seconds</td>\n","      <td>13.0 mins 25.96 seconds</td>\n","      <td>0.0 mins 2.05 seconds</td>\n","      <td>18.0 mins 52.49 seconds</td>\n","      <td>Well, friends, today we are going to discuss ...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>51</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>nature-of-society-individuals-and-groups-audio...</td>\n","      <td>openai/whisper-large-v3</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 43.84 seconds</td>\n","      <td>6.0 mins 32.19 seconds</td>\n","      <td>2.0 mins 26.82 seconds</td>\n","      <td>4.0 mins 31.76 seconds</td>\n","      <td>0.0 mins 3.30 seconds</td>\n","      <td>14.0 mins 39.68 seconds</td>\n","      <td>Well friends, today we are going to discuss t...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>20</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nature-of-society-individuals-and-groups-audio...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 27.04 seconds</td>\n","      <td>1.0 mins 1.36 seconds</td>\n","      <td>2.0 mins 15.83 seconds</td>\n","      <td>5.0 mins 30.72 seconds</td>\n","      <td>0.0 mins 2.73 seconds</td>\n","      <td>9.0 mins 47.84 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>20</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-base</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 19.28 seconds</td>\n","      <td>1.0 mins 29.89 seconds</td>\n","      <td>1.0 mins 12.10 seconds</td>\n","      <td>9.0 mins 45.20 seconds</td>\n","      <td>0.0 mins 1.42 seconds</td>\n","      <td>12.0 mins 48.54 seconds</td>\n","      <td>Well, first today we are going to discuss the...</td>\n","      <td>[\"1. What is the definition of society accordi...</td>\n","      <td>27</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 12.18 seconds</td>\n","      <td>1.0 mins 8.68 seconds</td>\n","      <td>1.0 mins 20.21 seconds</td>\n","      <td>7.0 mins 28.07 seconds</td>\n","      <td>0.0 mins 1.02 seconds</td>\n","      <td>10.0 mins 10.21 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>24</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 15.79 seconds</td>\n","      <td>1.0 mins 9.23 seconds</td>\n","      <td>1.0 mins 24.34 seconds</td>\n","      <td>5.0 mins 29.20 seconds</td>\n","      <td>0.0 mins 1.62 seconds</td>\n","      <td>8.0 mins 20.88 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>19</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 15.42 seconds</td>\n","      <td>1.0 mins 10.78 seconds</td>\n","      <td>1.0 mins 19.33 seconds</td>\n","      <td>5.0 mins 33.74 seconds</td>\n","      <td>0.0 mins 1.41 seconds</td>\n","      <td>8.0 mins 21.31 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>21</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 15.19 seconds</td>\n","      <td>1.0 mins 9.74 seconds</td>\n","      <td>1.0 mins 18.81 seconds</td>\n","      <td>5.0 mins 15.32 seconds</td>\n","      <td>0.0 mins 0.97 seconds</td>\n","      <td>8.0 mins 0.67 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>19</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 32.81 seconds</td>\n","      <td>1.0 mins 12.72 seconds</td>\n","      <td>3.0 mins 46.97 seconds</td>\n","      <td>7.0 mins 8.06 seconds</td>\n","      <td>0.0 mins 2.79 seconds</td>\n","      <td>12.0 mins 45.15 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of society accordi...</td>\n","      <td>21</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 34.79 seconds</td>\n","      <td>1.0 mins 13.49 seconds</td>\n","      <td>2.0 mins 58.15 seconds</td>\n","      <td>7.0 mins 38.80 seconds</td>\n","      <td>0.0 mins 3.92 seconds</td>\n","      <td>12.0 mins 33.11 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>[\"1. What is the definition of society accordi...</td>\n","      <td>21</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 17.30 seconds</td>\n","      <td>1.0 mins 12.76 seconds</td>\n","      <td>3.0 mins 3.79 seconds</td>\n","      <td>7.0 mins 41.26 seconds</td>\n","      <td>0.0 mins 1.79 seconds</td>\n","      <td>12.0 mins 17.99 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of a group in soci...</td>\n","      <td>13</td>\n","      <td>input_variables=['text'] template='\\n    You a...</td>\n","      <td>input_variables=['existing_answer', 'text'] te...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 18.42 seconds</td>\n","      <td>1.0 mins 15.76 seconds</td>\n","      <td>1.0 mins 29.36 seconds</td>\n","      <td>5.0 mins 37.52 seconds</td>\n","      <td>0.0 mins 2.08 seconds</td>\n","      <td>8.0 mins 44.12 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of a group accordi...</td>\n","      <td>9</td>\n","      <td>input_variables=['text'] template='\\n    You a...</td>\n","      <td>input_variables=['existing_answer', 'text'] te...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 15.08 seconds</td>\n","      <td>1.0 mins 12.03 seconds</td>\n","      <td>1.0 mins 26.99 seconds</td>\n","      <td>3.0 mins 52.08 seconds</td>\n","      <td>0.0 mins 1.53 seconds</td>\n","      <td>6.0 mins 47.81 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of a group accordi...</td>\n","      <td>10</td>\n","      <td>input_variables=['text'] template='\\n    You a...</td>\n","      <td>input_variables=['existing_answer', 'text'] te...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n","      <td>0.0 mins 12.98 seconds</td>\n","      <td>1.0 mins 13.92 seconds</td>\n","      <td>1.0 mins 30.33 seconds</td>\n","      <td>3.0 mins 40.21 seconds</td>\n","      <td>0.0 mins 1.60 seconds</td>\n","      <td>6.0 mins 39.15 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>['1. What is the definition of a group accordi...</td>\n","      <td>19</td>\n","      <td>You are an expert at creating questions based ...</td>\n","      <td>You are an expert at creating practice questi...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>ASR/Mod-01 Lec-03 Nature of society Individual...</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 9.63 seconds</td>\n","      <td>0.0 mins 49.86 seconds</td>\n","      <td>0.0 mins 12.92 seconds</td>\n","      <td>1.0 mins 58.69 seconds</td>\n","      <td>NaN</td>\n","      <td>3.0 mins 11.42 seconds</td>\n","      <td>Well first, today we are going to discuss the...</td>\n","      <td>[{'generated_text': '[INST] &lt;s&gt; You have Phd i...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>AudioFiles/javascript_mock.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 11.28 seconds</td>\n","      <td>1.0 mins 6.84 seconds</td>\n","      <td>0.0 mins 14.00 seconds</td>\n","      <td>0.0 mins 57.40 seconds</td>\n","      <td>NaN</td>\n","      <td>2.0 mins 29.73 seconds</td>\n","      <td>Hello everyone, welcome back to another inter...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>AudioFiles/infosys_interview.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 9.43 seconds</td>\n","      <td>0.0 mins 41.36 seconds</td>\n","      <td>0.0 mins 14.31 seconds</td>\n","      <td>0.0 mins 52.23 seconds</td>\n","      <td>NaN</td>\n","      <td>1.0 mins 57.50 seconds</td>\n","      <td>Good afternoon sir. Hmm, pooruvi, are you ner...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>AudioFiles/campus_placement.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 11.10 seconds</td>\n","      <td>0.0 mins 50.31 seconds</td>\n","      <td>0.0 mins 14.08 seconds</td>\n","      <td>0.0 mins 40.31 seconds</td>\n","      <td>NaN</td>\n","      <td>1.0 mins 55.97 seconds</td>\n","      <td>Kajal. Alo, good afternoon sir. How are you? ...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>AudioFiles/campus_placement.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 9.18 seconds</td>\n","      <td>0.0 mins 50.67 seconds</td>\n","      <td>0.0 mins 14.18 seconds</td>\n","      <td>0.0 mins 45.60 seconds</td>\n","      <td>NaN</td>\n","      <td>1.0 mins 59.79 seconds</td>\n","      <td>Kajal. Alo, good afternoon sir. How are you? ...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>AudioFiles/tcs_interview.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 16.59 seconds</td>\n","      <td>1.0 mins 41.34 seconds</td>\n","      <td>0.0 mins 14.23 seconds</td>\n","      <td>0.0 mins 38.43 seconds</td>\n","      <td>NaN</td>\n","      <td>2.0 mins 50.75 seconds</td>\n","      <td>So, if you click points to be shared because ...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>AudioFiles/lstm.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 12.83 seconds</td>\n","      <td>0.0 mins 40.68 seconds</td>\n","      <td>0.0 mins 14.11 seconds</td>\n","      <td>0.0 mins 49.84 seconds</td>\n","      <td>NaN</td>\n","      <td>1.0 mins 57.63 seconds</td>\n","      <td>So now we are going to discuss LSTM and we ar...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>AudioFiles/lstm.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 11.16 seconds</td>\n","      <td>0.0 mins 41.05 seconds</td>\n","      <td>0.0 mins 14.22 seconds</td>\n","      <td>1.0 mins 7.19 seconds</td>\n","      <td>NaN</td>\n","      <td>2.0 mins 13.79 seconds</td>\n","      <td>So now we are going to discuss LSTM and we ar...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>AudioFiles/rnn.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>NaN</td>\n","      <td>0.0 mins 16.13 seconds</td>\n","      <td>0.0 mins 55.62 seconds</td>\n","      <td>0.0 mins 14.20 seconds</td>\n","      <td>0.0 mins 28.30 seconds</td>\n","      <td>NaN</td>\n","      <td>1.0 mins 54.42 seconds</td>\n","      <td>Welcome to the next episode of the Nature of ...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AudioFiles/rnn.mp3</td>\n","      <td>openai/whisper-tiny</td>\n","      <td>mistralai/Mistral-7B-Instruct-v0.2</td>\n","      <td>None</td>\n","      <td>0.0 mins 13.13 seconds</td>\n","      <td>0.0 mins 56.00 seconds</td>\n","      <td>0.0 mins 14.24 seconds</td>\n","      <td>0.0 mins 30.05 seconds</td>\n","      <td>None</td>\n","      <td>1.0 mins 53.59 seconds</td>\n","      <td>Welcome to the next episode of the Nature of ...</td>\n","      <td>[INST] &lt;s&gt; You have Phd in history and best in...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89fc3cd3-8060-49bc-80d3-a120a4fa2a14')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-89fc3cd3-8060-49bc-80d3-a120a4fa2a14 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-89fc3cd3-8060-49bc-80d3-a120a4fa2a14');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4e69a6a7-dc33-43e1-b408-6cf2ada1a46e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e69a6a7-dc33-43e1-b408-6cf2ada1a46e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4e69a6a7-dc33-43e1-b408-6cf2ada1a46e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7d68398a-c108-465e-a9c0-ad46ac63c1be\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7d68398a-c108-465e-a9c0-ad46ac63c1be button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"AUDIO_FILE_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"ASR/Mod-01 Lec-03 Nature of society Individuals and groups [TubeRipper.com].mp3\",\n          \"AudioFiles/tcs_interview.mp3\",\n          \"nature-of-society-individuals-and-groups-audio/lecture.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_MODEL_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"openai/whisper-large-v3\",\n          \"openai/whisper-base\",\n          \"openai/whisper-small\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TG_MODEL_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"meta-llama/Meta-Llama-3-8B-Instruct\",\n          \"mistralai/Mistral-7B-Instruct-v0.2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EMBEDDING_MODEL_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sentence-transformers/all-MiniLM-L6-v2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_LOADING_DURATION\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"0.0 mins 32.81 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR_S2T\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"1.0 mins 12.72 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TG_LOADING_DURATION\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"3.0 mins 46.97 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TG_DURATION\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"7.0 mins 8.06 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EMBEDDING_LOADING_DURATION\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"0.0 mins 3.92 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TOTAL_DURATION\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"12.0 mins 45.15 seconds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S2T_OUTPUT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" So now we are going to discuss LSTM and we are going to talk about how the LSTM works. Why it works? We talked about Argonen and the last lecture and in this lecture we are going to discuss about LSTM and how it solves the problems of Argonen. So in the last article which is today and down below we talked about the third category of the neural network. I recorded a neural network, we briefly discussed what they are and how do they work? Why does them working that discuss that were very helpful? If you haven't read the article here, you go. I would suggest you get deep understanding of the vanilla running before you get started with the LSCM. By the end of this article I told you about the limitation of awareness. The limitations are in half to be if we get an overview of what the limitations were. They are sequential and lectures. The input sequences are on your process one after the other. The T-Lex input being called dependent on the previous one. This increase is the latency and not per generation. They are not good for our long sequences. This is a deal breaker when it comes to an LP. The maximum memory rate attention of RNA goes back to 10 sequences at best. This is bad when it comes to sentences because the smallest of paragraphs are 32, 30 to 40 words long. Sure you can work with small sentences but it's not really useful because not much information can be analyzed at a single time. The reason it is unable to do that is because of its limited memory retention. Although the LSTM does not deserve the first problem that can't traumatize but he'll talk about you later. It does resume the deal breaker problem. The long-term memory potential LSTM is known for being able to realize that this approach is 1000 sequences. It's 100x, I'm for sure. Yes LSTM had had more success in the study of Dan Newerman. Go mix his looks like so I guess. But not the way we're going to talk as one could experiment. LSDM regret the data but step foot on this as my story papers of course. So the burning question is how do we retain non-temdemry? How do we ensure that the lasting effects of the person who passes so far, stay throughout the equation if it is rather than enough? To start it off, we have a sad bitrier assumption that we have a patient that figured out how to compress all of our past and current, that sequences into a single vector. We will call these vectors cells or our context. Although I would have gone with Kashi, where I vector myself, though I get that it is in that catchy, right, I guess. If you don't get the reference, what your dose bizarre and I don't know. Let's assume that we are in the middle of the duration, and we have successfully compressed all the team-in-1 input vectors. We have seen so far in the context. It is stored in its compressed form of CT-1, but storing two machine-formation ingest one vector might make our prediction slightly noisy. So what we want to do instead is create a mechanism to forget some of the context which is a relevant noise. So in other words FFT and VcFT e minus 1, we want to multiply the context vector by a forget vector which will be more which will remove the irrelevant noise and keep the relevant context from the contrast context of all of the previous values. See something like this. Assuming that FFT here is a forgetfulness left it that somehow magically has the ability to erase noise from our context. The next step is to get the current compressed vector c- of t- and then extract useful information out of it. So something like this, IFT and DC of dash, C, prime of t. So now, we have useful processed context from the past. T minus 1 context. And we have useful processed context from the teeth input network. The only thing left to do is the form our new context by adding them both. CFT equal to FFP and the C of T minus 1 which was the output from our first theoretical hypothesis and the second is I have which is added to I have P into C prime B which came from the R second theoretical hypothesis. The context factor of self-state vector is meant to score a stole the long term information that is the key to the overall understanding of the input. Long term memory is great and all, but a human doesn't just make decisions based on long term memory. When the real text, you simply use your long term memory that stores the ability to read English to understand it, it might be tempting to say yes but give it a second. You also maintain a local context understand the recent text before along the side connect it's alongside the current text and you do your long term understanding or just story line to follow along and to be understand what is going on. It is the same with LSTM. You also need to maintain a shock-term memory story in these years. We need some architecture that will take the current output and overall context of the past and produce a current local context. Something like this, and produce a current local context. Something like this, HFT, Equality, Tarn Edge of CFD, into OFT. So after putting it down, you get the following comment. The first is to kill it, forgetfulness, which is going to go through its own recurrent neural network, and then there is C prime of it, which is also going to go through its own recarret neural network and then there is C prime of T which is also going to its own separate neural network both of those and we of course need the i of t which is also going to go through a separate neural network C of t which is also going to separate M C of t is going to be a sum of of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the function of the Red is going to generate the final hidden step which is going to be tan and should see a p-multi-c by the output there. The output of the R. The comfort this can be explained with the same format of the mathematical equation. We are going to use PyTorch for this. The first of this is going to set the print options of the sign mod equal to the first, this allows us to see bigger numbers, it turns up space, but for smaller numbers it just makes more sense for us to see normal floating point efforts. We initialize an empty arrays and for hidden state an initial cell state we initialize the random weights for all of the layers that I mentioned before and then we set start up a loop which is going to first generate the prerequisite layers like C dash, C, P, F of T and I of T and then it's going to use the previous hidden state to generate the self state, the current self state and the current self state will be used in generated output. Just like that, it is going to generate this high-edit state of the current output and it is trying to keep using that current output to generate the next output. I am going to store each of the hidden state in a list. Okay. Let's leave the answer is to can remember the last set of events and I will give you the following explanation for vanishing and exploding data problem. And then the issue is that the function F is going to be a tannish motion. So every value that conducts it is going to be between minus 1 and 1. Depending on whether the scale of the text values and time, what I'm the scale of x values and the tannish values, the gradients are either going to become really really small or a random derivation or a is another activation function, it may become really, really massive over long sequences. And we take the gradients of your current A, where networks mean we take the gradient of the tan inch function, repeat it or any function repeated. The function derivative chilling in which multiple tan inch or new values are being multiplied converged. But tan inch is between minus 1 and 1, the multiplication is such. Small values are just 3 names to shrink down, exponential. The long-term condition is R, the smaller that is going to become. Counteractively, if it is the same with very reactivated sequences, sequences just set the contracts for a particular, because the minimum value of the null can take4, which is the minimum value that the latent take is 0. And the maximum value that everything takes is positive infinity. If the service model on large travels must apply to our constant EO 3D values, then the significance of the great introduced and the significance of the reactivation function increases. If the update of its based on this fact, then not only will you have neural network gain meaningless output it may even simply output nands. Because of this explicitly because of this explicitly, it's explicitly sending wrong sequences inside your aromand and make it explode or shrink down causing the vanishing and exploding dating problem. But even when anSTM, our dependencies are vegan, vegan, vegan, and state-sensis. So what in the world is all this over? Complete, complete, complete, complete, complete computation as well. How does doing so many computation and distributing the flow of information to dates have been in vanishing dating?. The greatest is still going to be long chains. If anything is going to be a lot more complex, because of so many gate inside of them. Not to mention now we're also using sigmoid activation function. This is even more in case of gate advantage because the letter letter of sigmoid is a sigmoid of x into 1 minus sigmoid of x. If you have 0.99, it will be multiplied by 0.0.1, shrinking the value to a really really small number. The maximum value that can be attained in the rest of the product is 0.25, shaming it will just make it shrink the picture in the mirror. It seems that it is likehokriter and your nishmithuva have screwed us over for a time. Well, except they did, the van shimdhryna and Babur ultimately possessed because of the following issue in our limits by updating the weights of the RNN and the long chain of their movements. Each of which is either a damage function or a value function I've made before before and this part is the value chain we have exploded in the end problem, p and d of h. However, the stress state in the same does not really depend on tannages or same-mine activation. For example, take a look at this equivalence to a t equal to c of t minus 1 into f of t plus c of the c prime of t into i of t. Here, when you think the derivative of c of t with respect to c of t minus 1, you get f of t plus f of t with the c dash of t into i of t, derivative of c dash of t into i of t is the C, dash of t into I of t, derivative of C, dash of t into I of t, we respect to the derivative of C and I, which C of t is the one I respect. Whatever the derivative of the second term is, the more important part is that the gradient cannot be zero if the numbers are edited. Here's what I'm talking about. Let's assume that somehow all of the gray in the previous stage for a second time just stand to see. Now because the mirror net materialized to these terms are going to see up on the next iteration, in order to minimize the angle, the mirror net material is still pd and just the bits of a 50 in such a way that a 50 vector range zero. Just a judgment for petriving not that FMP is here. Which will start a chain of events that will not yet be there. The next time it will be here. And so the magic I talked about while describing the LSTM architecture is the newer network attempting to reduce law or reduce laws by undertaking the way. will reduce loss by end taking the weight. This is how the LSTM allows for a room of non-zero elements in their trading. This and this are basically a catch problem. Now let's talk about the cons. LSTM is still sequential. Not only that because of the multiple gx system is over throughout the complex and slow, LSTM despite being a significant improvement over vanilla R&N, on the course of 1000 tokens, takes significantly extremely long paragraphs. And because of it, sequential nature and higher number of foundations, the longer sequences of texts that have high latency power. It is an identified word, a correlation is wrong. It has a hard time associating words with other words it has seen in the past. This type of neural network might be great for sentiment classification tasks. It went to the generation of language or translation of language. It did not perform nearly as well. In the last article I provided intuition on the components of the Aranananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananananan or in father classes are on an in-base and on an in-base. On an in-base has the following in-head-up. On an in-base, and the same, and the same. And on an in-cell-base has the following in-head-up. On an in-cell, and the same, and the same, and the same. LSTM cell and Gioru-usa. In LSTM class of PyTorch uses LSTM cells to stack itself based on the LSTM. Input you provide. The inputs follow the same rules as the LSTM. Now, the LSTM is used to stack LSTM. together input signs which is the size of the input hidden side which is the number of neurons in the hidden layer batch first which if you set it to true you have input data shape does back size into sequence length into D into input size by default the data should be shaped as sequentially into back side. You can answer provide initial sense set and initial hidden state of your estimate. You can also set something called the Pro Edge size where you are going to create projection as a DL is the MPA and introduce the amount of computations. The explanation for which is going to create projection as a DL is the embryo and introduce the amount of computations. The explanation for which is provided here. And the last theme projected layer is an RNA that learns long term dependencies between times X in times X. And see, third state of this in projected dynamical ways. To compress a beam learning network, it will use projective layers. A projective layer is a type of loop learning layer that enables compression, but it uses the number of stone and a number. The layer introduces the variable projector matrices. Here, the face is multiplications of the form that we ask that the view is multiplications of the form that we have X, where W is a lot of matrix, with the multiplication of WQ, Q transpose X, and storage to Q and Q and Q and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q, and Q Projecting X into a lower dimensional space is in queue typically requires less number than I thought and the random number for our atmosphere is can have a similar and strong prediction at the end. Talking about the output of the atmosphere. So we receive three to say 3 sets of hand codes, 3 sets of our codes. I would put our put selector, C0 and H vector. Our put is a usual, is as usual, the top must rose, 10 in the state vector. I would put up the style in my shell, just like in the Venena Aranam. The reason we don't output cell state is because the cell state is perpetuated to the role to the X and the steam cell at the same time. So throughout all the sequence of the top most row, we are using the same cell state just at different points in the line. The only important cell state is what comes out at The correct step is to find out the last corner. And then we enter. So we look at the code about here. You can actually use all of these parameters here. I've set the batch size equal to 15 to 15 batches. size we put it into that for pin patches is sequence length of points so each sequence is up there in steps there's input size which each vector inside input is each each row is going to be four part of it called this and the hidden size is 6, so the hidden name is I'm going to have 6 neurons. The number of layers is 20 and so we are stacking 28 current here in the network where the map is 1 or 2 you can keep. You can select one of them in based on the D, you know, the D1 by directional one or a D1 to the direction of the model, you can switch between them depending on what you like. When defining the ND random vector x and we are sending it through the R and then by setting the parameters as follows, is from PyTorch using the RSTM itself. And then in the output and then we are seeing the shapes of the different outputs that we got, which is the output size, the hidden states size and the cell states name. And that's how it's done. In the overall, all of the same LSTM is as well, all of LSTM is right. After this architecture, there were a few modifications to make it the LSEM architecture. It used the number of computations in LSEM being widely obtaining the performance. This was done using GRA or FATED in the actual year. These were computationally less hydrogen perform just as well. As LSEM although in my opinion LSEM some of the theories of this principle than G.I.A. in inverse, it doesn't really have the understanding of natural language as we do. It's in the words for basic language as, like sentence, classification and doing something, somewhat decent next word predictions. It's like the typical ML junior dam who knows how to use the APIs, but doesn't really understand how the ZAPL is work. knows how to use the APIs, but doesn't really understand how the APIs work. I'm starting myself, don't put it's not directed towards using a developer. However, there was a storm brewing in the mind of Google Trend. And it was about to take the world under its command. This next adventure is going to be the death of regard neural networks. If we discuss them in the next chapter, till then, we'll talk about it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GeneratedQNA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"['1. What is the definition of society according to the text?\\\\nHelpful Answer: According to the text, a society is a complex configuration of groups and subgroups within a larger entity, with interactions between these groups leading to cooperation, conflict, interests, and emotions. It is an aggregate of people with an identity, regulated by norms and governed by international conventions and organizations, with mobility of people and capital between countries. The text also suggests that world society is emerging as the largest group, with individuals identifying as world citizens and interacting on a global scale.', '2. What is the difference between an aggregate and a group?\\\\nHelpful Answer: An aggregate is a collection of individuals, while a group is a collection of individuals with interaction and a sense of unity among its members. In other words, a group has additional characteristics beyond just being an aggregate, such as regular interaction and a shared identity or purpose.', \\\"3. What are the main characteristics of a perfect group?\\\\nHelpful Answer: A perfect group, also known as a fourth degree group, is a collection of individuals with a number of characteristics. These characteristics include interaction among the members, a sense of unity or belongingness, organization, and regulation of behavior according to certain rules. This type of group can have a significant impact on an individual's thinking, feelings, behavior, belief systems, values, and norms. Examples of perfect groups include communities, such as a village community, which are independent of individuals' thinking, feeling, and acting. In such groups, individuals are born into the community and the behavior is regulated by certain rules.\\\", '4. What is the difference between values and norms?\\\\nHelpful Answer: Values are the standards of behavior, the matters of right and wrong, good and bad, beautiful and ugly, so aesthetics. They are the standards of behavior. Norms, on the other hand, are the guidance or regulations that help individuals pursue those values in society. Norms are the rules that guide behavior in accordance with the values of society. While human behavior is learned and not instinctive, norms exist to help individuals follow the values of society and maintain social order.', '5. How is human behavior learned according to the text?\\\\nHelpful Answer: Human behavior is learned and not instinctive or biologically determined. It is influenced by socialization, norms, culture, and organizations. The text mentions the importance of folkways, mores, and taboos in shaping human behavior. Folkways are the unwritten rules that govern most of our behavior and are based on emotions and traditions. Mores are the rules that are enforced by social sanctions and are based on moral values. Taboos are the rules that are based on superstitions and are often prohibited by law. The text also discusses the importance of social organizations in shaping human behavior. In Indian society, for example, there are various groups such as landowners, tenants, sharecroppers, priests, carpenters, blacksmiths, and mineral workers. Each village has its own unique set of groups and subgroups, and interaction within these groups is governed by the norms of society. The text also mentions that human behavior is learned from a very young age and that we become addicted to folkways. Even when we migrate from one community to another, the community survives and continues to shape our behavior. The text also mentions that there is a factual order and a normative order in society, and that both are necessary to understand a society. In conclusion, human behavior is learned and shaped by a complex interplay of socialization, norms, culture, and organizations.', '6. What are the different types of norms mentioned in the text?\\\\nHelpful Answer: The text mentions three major categories of norms: folkways, mores, and taboos. Folkways are the unwritten rules and customs that govern our daily behavior and are largely based on tradition. Mores are the social norms that are considered essential for the functioning of society and are enforced by social pressure. Taboos are the cultural prohibitions that are strictly enforced and violating them can result in social ostracism or even physical harm. The text also mentions that there is a continuum between norms based on adherence to them and emotions attached to them, and that human behavior is largely learned and not instinctive.', \\\"7. What is the difference between most and taboos?\\\\nHelpful Answer: The difference between most and taboos lies in the emotions attached to them. Most are norms that are generally accepted and followed in a society, while taboos are norms that are strongly prohibited and carry a great deal of emotional weight. Violating a taboo can result in guilt and suffering throughout one's life, while violating a most may not have any significant consequences. Additionally, most are often addictive and automatic, while taboos require conscious thought and decision-making. From a sociological perspective, both most and taboos serve to regulate behavior and maintain social order, but the emotional consequences of violating a taboo are much more severe.\\\", '8. What is the role of emotions in adhering to norms?\\\\nHelpful Answer: Emotions play a significant role in adhering to norms. Norms not only guide human behavior but also evoke emotional responses. Violating a norm can result in emotional shock or guilt, which serves as a deterrent to further deviation from the norm. Emotions help to strengthen the bond between individuals and their communities, reinforcing the normative order. Additionally, emotions can motivate individuals to uphold the values and interests of their society, even if it means sacrificing their own individual interests. Overall, emotions play a crucial role in shaping human behavior and maintaining social order.', '9. What is the difference between primary and secondary groups?\\\\nHelpful Answer: Primary groups are smaller in size, most of the interaction is face-to-face, and they shape our lives more than secondary groups. Primary groups include families, while secondary groups include organizations such as schools, churches, and workplaces. In primary groups, there is a greater sense of emotional attachment and a stronger sense of community. In contrast, secondary groups are larger and more impersonal, and interaction is often more formal and transactional. While primary groups may be more influential in shaping our identities and values, secondary groups may be more important for fulfilling practical needs and advancing our careers. Ultimately, both primary and secondary groups play important roles in our lives and contribute to our overall socialization.', '10. How does gender influence the distribution of power in a family?\\\\nHelpful Answer: In patriarchal societies, males are generally considered more powerful than females. However, not all males or females are equally powerful or powerless. The oldest male in the family, often the owner of movable and immovable property, holds the most power. Among females, the symbolic mother-in-law holds significant power. The division of labor within the family is also structured by gender, with women following a more rigid daily routine and having less autonomy than men. In some cases, studies have shown that in pre-industrial societies, mothers held more power than fathers. However, with industrialization, economic development, modernization, and the influence of border religions, power has been taken away from women and given to men. This female-male distinction is also important within each family, with males and females having different rights, obligations, and expectations.', \\\"11. What is the role of the oldest male in a patriarchal society?\\\\nHelpful Answer: In a patriarchal society, the oldest male is considered the most powerful. He is the owner of movable and immovable property, and wears a symbolic hat that signifies his power. Among females, the symbolic mother-in-law is more powerful. However, not all males or females are equally powerful or equally powerless. The oldest male's power is not absolute, and there may be other groups and hierarchies within the society that also hold power. For example, in some societies, the breadwinning adult male is seen as very important, and in times of crisis, society may have to decide what to do with powerless people such as children and old people. In some extreme cases, old people may be expected to commit suicide or even be killed during times of crisis. The role of the oldest male in a patriarchal society is complex and multifaceted, and his power is not absolute but relative to other groups and individuals within the society.\\\", '12. What is the difference between a community and a society?\\\\nHelpful Answer: A community is a smaller, more cohesive group, often based on shared identity or location, while a society is a larger, more complex collection of individuals and groups. Communities often have a strong sense of belonging and shared values, while societies are characterized by diversity and complexity. In a community, interactions are more face-to-face and members have a greater sense of connection, while in a society, interactions are more impersonal and there is greater social distance between individuals. Communities can exist within societies, and societies can be made up of many communities. For example, a village might be a community, while a country might be a society made up of many villages and other communities.', '13. What are the different types of groups mentioned in the text?\\\\nHelpful Answer: The text mentions different types of groups, including first degree groups (crowds and mobs), higher order groups (community, organization, and structure), and fourth degree groups (independent groups like village communities). The text also mentions various groups within society, such as landowners, tenants, sharecroppers, priests, carpenters, blacksmiths, mineral workers, and sweepers. Additionally, the text discusses the importance of family as a primary group and the significance of the female-male distinction within families.', '14. How do interactions between groups occur?\\\\nHelpful Answer: Interactions between groups can occur through cooperation, conflict, interests, and emotions. These interactions can be regulated by norms and organizations within society. For example, in Indian society, there are various groups such as landowners, tenants, priests, carpenters, blacksmiths, and sweepers. These groups exist within the larger society of India and interact with one another in various ways. The behavior of individuals within these groups is governed by the norms of society. For instance, in a village, there may be landowners, tenant families, and families of landless laborers. Within each group, there may be subgroups. For example, within the group of landowners, there may be families of different sizes. Within the group of tenant families, there may be families of different sizes as well. The interactions between these groups can be regulated by the norms of society, such as the division of labor, the distribution of resources, and the rules of behavior. For example, landowners may provide land for tenant families to cultivate in exchange for a portion of the harvest. Similarly, families may have specific roles and responsibilities within their group, such as caring for the elderly or educating the children. These interactions between groups and subgroups help to shape the larger society and create a complex configuration of social organization.', '15. What is the concept of world society according to the text?\\\\nHelpful Answer: According to the text, world society is an emerging concept that refers to the largest group in which all individuals in the world are members. It is characterized by increasing interactions, mobility of people and capital, and the existence of international organizations and conventions that regulate behavior and promote cooperation and development. World society is seen as a complex configuration of various groups and subgroups, with interactions between them based on cooperation, conflict, interests, and emotions. The text suggests that world society is emerging due to the increasing globalization and interconnectedness of the world, and that it is becoming increasingly important for individuals to identify as world citizens rather than just being members of their national or local groups. The text also emphasizes that world society is not just a factual entity, but also has a normative order that governs behavior and shapes human interactions.', \\\"16. How does the text describe the relationship between individuals and society?\\\\nHelpful Answer: The text describes society as a collection of individuals, with individuals forming groups that interact and have a sense of unity. Sociologists are more interested in higher order groups, which affect our thinking, feelings, behavior, belief systems, values, and norms. The text also discusses the concept of in-groups and out-groups, and the minimal degree of organization required for a group. The text also discusses the importance of interaction and unity in groups, and the concept of fourth degree groups, which are independent of individuals' thinking, feeling, and acting. The text also discusses the importance of folkways, which govern most of our behavior and are the alphas and omegas of human behavior. The text also discusses the importance of world society, which is emerging due to the movement of people and interaction between countries, and the increasing identification of individuals with world citizenship.\\\", '17. What is the significance of the founding fathers of sociology mentioned in the text?\\\\nHelpful Answer: The founding fathers of sociology mentioned in the text are the pioneers who laid the groundwork for the scientific study of society. They are significant because they provided the theoretical framework and concepts that continue to shape the field of sociology today. By studying their works, we can gain a deeper understanding of the nature of society and the role of sociology in explaining social phenomena. Some of the founding fathers mentioned in the text include Auguste Comte, Emile Durkheim, and Max Weber. Comte is considered the father of sociology, as he coined the term and established the first sociology department. Durkheim is known for his studies of social cohesion and the role of social institutions in shaping society. Weber is famous for his theories on the role of ideas and rationality in shaping social action. Overall, the founding fathers of sociology have had a profound impact on the development of the field and continue to be studied and debated by sociologists today.', '18. How does the text describe the impact of religion on society?\\\\nHelpful Answer: The text describes religion as an essential part of society, shaping the normative order and influencing human behavior. It mentions that religious practices and beliefs constitute a significant portion of folkways, which are the unwritten rules and customs that govern behavior in a society. The text also mentions the existence of taboos, which are religious prohibitions that guide behavior and are deeply ingrained in society. The text suggests that religion provides a moral framework for individuals and communities, guiding their actions and shaping their values. It also mentions the role of religious leaders and institutions in maintaining social order and providing a sense of community and belonging. Overall, the text portrays religion as a powerful force that shapes the normative order and influences human behavior in significant ways.', \\\"19. What is the role of interaction and unity in forming a group?\\\\nHelpful Answer: Interaction is an essential element in forming a group as it allows members to communicate and work together towards common goals. Unity, or a sense of belongingness, is also crucial as it creates a sense of identity and cohesion among group members. These two factors, along with a minimal degree of organization, contribute to the formation of higher order groups that can significantly impact individuals' thinking, feelings, behavior, belief systems, values, and norms.\\\", \\\"20. How does the text describe the impact of industrialization and urbanization on society?\\\\nHelpful Answer: The text describes how industrialization and urbanization have led to the emergence of a larger entity called world society. With the movement of people, interaction, and the formation of new groups and subgroups, there is a complex configuration of groups and subgroups within this larger entity. The text also mentions the importance of identity, unity, and meaning in society, which have become more significant in the context of world society. The text also mentions the importance of values and norms in human behavior and how they guide and regulate human behavior in pursuance of the values of society. The text also mentions the distinction between factual order and normative order and the importance of understanding both to understand a society. The text also mentions the impact of industrialization and urbanization on traditional communities, such as the village community, and how strong identities with these communities can still exist even in the context of world society. The text also mentions the importance of preserving every inch of one's motherland and the emotional attachment to one's community. Overall, the text suggests that industrialization and urbanization have led to the emergence of a more complex and interconnected world society, but traditional communities and their values and norms continue to play an important role.\\\", \\\"21. What is the significance of the concept of 'in groups' and 'out groups' in the text?\\\\nHelpful Answer: The concept of 'in groups' and 'out groups' refers to the distinction between groups to which an individual feels a sense of belongingness and identification, and those from which they feel excluded or different. In groups are those in which an individual feels a strong sense of unity and belongingness, while out groups are those in which they feel excluded or different. This distinction is significant because it can influence an individual's thinking, feelings, behavior, and belief systems, as well as their interactions with members of different groups. The text discusses how groups can be organized based on various characteristics, such as interaction, unity, and organization, and how these characteristics can contribute to the formation of in groups and out groups. The text also mentions how individuals can identify with larger groups, such as the society of India, and how there can be interactions and relationships between different groups within a larger society. The concept of in groups and out groups is also relevant to discussions of social inequality and discrimination, as individuals may feel a greater sense of belongingness and solidarity with those who share similar characteristics or experiences, and may exclude or discriminate against those who are perceived as different or out group members.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 51,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PROMPT_USED\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"input_variables=['text'] template='\\\\n    You are an expert at creating questions based on studying material and source pdf.\\\\n    Your goal is to prepare a student or graduate for their exams.\\\\n    You do this by asking 10 and only 10 questions about the text below:\\\\n\\\\n    ------------\\\\n    {text}\\\\n    ------------\\\\n\\\\n    Create 10 questions that will prepare the students or graduates for their tests.\\\\n    Make sure not to lose any important information.\\\\n\\\\n    QUESTIONS:\\\\n    '\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"REFINED_PROMPT_USED\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"input_variables=['existing_answer', 'text'] template='\\\\n    You are an expert at creating practice questions based on studying material and online pdfs.\\\\n    Your goal is to help a student or graduate prepare for a exam.\\\\n    We have received some practice questions to a certain extent: {existing_answer}.\\\\n    We have the option to refine the existing questions or add new ones.\\\\n    (only if necessary) with some more context below.\\\\n    ------------\\\\n    {text}\\\\n    ------------\\\\n\\\\n    Given the new context, refine the original questions in English.\\\\n    If the context is not helpful, please provide the original questions.\\\\n    QUESTIONS:\\\\n    '\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"p2-JDfU2IVK4","executionInfo":{"status":"error","timestamp":1716298552423,"user_tz":-330,"elapsed":443,"user":{"displayName":"OpenEyes VO","userId":"09656303119636152231"}},"outputId":"fc0bcbee-1478-4827-dff8-71d47346bbe1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-00cf07b74dcd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6kyJM6quPcfg"},"execution_count":null,"outputs":[]}]}